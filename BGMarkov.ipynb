{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple background Markov model in Pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not clear how pyro.plate function specifies conditional independence. I have 2 competing hypotheses for how it works:\n",
    "1. (Null) If we didn't separate various latent/observed variables using pyro.plate, AND did't specify in the guide the dependence of given variable on a previously sampled one, pyro won't automatically and explicitly assume some kind of dependence! All pyro.plate does is it will simplify sampling and various other calculations the model performs when the plate screams INDEPENDENT!\n",
    "2. (Alternate) By some mechanism I'm not aware of, pyro will construct will construct some conditional dependence on the variables not specified by a pyro.plate as independent! (How's that even possible if the involved variables are potentially real and unbounded?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pyro\n",
    "from pyro import distributions as dist\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll generate some DNA data from just a second order Markov model without assuming any motifs or modules. Here, we'll choose the Markov model in a randomly generated fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "prior = dist.Dirichlet(torch.tensor([1., 1., 1., 1.])) # type: ignore\n",
    "# Distribution from which Markov probabilities will be drawn from\n",
    "phi = prior.sample([4, 4])\n",
    "print(phi.shape)\n",
    "# \"phi\" describes a second order Markov distribution over DNA base pairs\n",
    "# for instance, phi[2, 3, 0] means probability of 0th BP conditioned on\n",
    "# BPs 2 and 3 to appear before it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the various conditional probabilities that phi represents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['(0, 0)', '(0, 1)', '(0, 2)', '(0, 3)',\n",
    "        '(1, 0)', '(1, 1)', '(1, 2)', '(1, 3)',\n",
    "        '(2, 0)', '(2, 1)', '(2, 2)', '(2, 3)',\n",
    "        '(3, 0)', '(3, 1)', '(3, 2)', '(3, 3)']\n",
    "\n",
    "flat_phi = np.reshape(phi, [-1, 4]) #\n",
    "\n",
    "df_phi = pd.DataFrame({'Conditioned BP': rows, \n",
    "                   'P(0)': flat_phi[:, 0],\n",
    "                   'P(1)': flat_phi[:, 1],\n",
    "                   'P(2)': flat_phi[:, 2],\n",
    "                   'P(3)': flat_phi[:, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conditioned BP</th>\n",
       "      <th>P(0)</th>\n",
       "      <th>P(1)</th>\n",
       "      <th>P(2)</th>\n",
       "      <th>P(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>0.265847</td>\n",
       "      <td>0.278432</td>\n",
       "      <td>0.353446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.213438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.469061</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.212499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>0.190408</td>\n",
       "      <td>0.320309</td>\n",
       "      <td>0.394577</td>\n",
       "      <td>0.094706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0.130510</td>\n",
       "      <td>0.691025</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.119028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.182082</td>\n",
       "      <td>0.208129</td>\n",
       "      <td>0.075353</td>\n",
       "      <td>0.534436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.893628</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.049326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.027103</td>\n",
       "      <td>0.150291</td>\n",
       "      <td>0.240775</td>\n",
       "      <td>0.581830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>0.066440</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.099284</td>\n",
       "      <td>0.643416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>0.258359</td>\n",
       "      <td>0.673523</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>0.028271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>0.125745</td>\n",
       "      <td>0.201966</td>\n",
       "      <td>0.120524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.289173</td>\n",
       "      <td>0.247635</td>\n",
       "      <td>0.401082</td>\n",
       "      <td>0.062109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>0.354409</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.175206</td>\n",
       "      <td>0.430860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.352572</td>\n",
       "      <td>0.378530</td>\n",
       "      <td>0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.203156</td>\n",
       "      <td>0.307503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.099723</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>0.098356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conditioned BP      P(0)      P(1)      P(2)      P(3)\n",
       "0          (0, 0)  0.102274  0.265847  0.278432  0.353446\n",
       "1          (0, 1)  0.035241  0.013038  0.738283  0.213438\n",
       "2          (0, 2)  0.068244  0.469061  0.250197  0.212499\n",
       "3          (0, 3)  0.190408  0.320309  0.394577  0.094706\n",
       "4          (1, 0)  0.130510  0.691025  0.059438  0.119028\n",
       "5          (1, 1)  0.182082  0.208129  0.075353  0.534436\n",
       "6          (1, 2)  0.893628  0.052813  0.004233  0.049326\n",
       "7          (1, 3)  0.027103  0.150291  0.240775  0.581830\n",
       "8          (2, 0)  0.066440  0.190860  0.099284  0.643416\n",
       "9          (2, 1)  0.258359  0.673523  0.039847  0.028271\n",
       "10         (2, 2)  0.551765  0.125745  0.201966  0.120524\n",
       "11         (2, 3)  0.289173  0.247635  0.401082  0.062109\n",
       "12         (3, 0)  0.354409  0.039524  0.175206  0.430860\n",
       "13         (3, 1)  0.181983  0.352572  0.378530  0.086914\n",
       "14         (3, 2)  0.475099  0.014243  0.203156  0.307503\n",
       "15         (3, 3)  0.099723  0.016313  0.785607  0.098356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a cell in the above table, if the left column \"Conditioned BP\" has value (i,j) and the top row P(k), then the value in the cell represents this conditional probability: $P(X_u=k| X_{u-2}=i, X_{u-i}=j)$ for a position u in a DNA sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # Length of DNA sequences\n",
    "batch = 50 # Size of batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating a batch of DNA sequences based on the Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((batch, n), dtype=int)\n",
    "g = np.random.default_rng()\n",
    "phi2 = phi.numpy() #Converted to NumPy array\n",
    "\n",
    "for i in range(batch):\n",
    "    prob = np.mean(phi2, axis=(0, 1))\n",
    "    X[i, 0] = g.choice(4, p=prob) #Marginalizing for positions 1,2\n",
    "    prob = np.mean(phi2, axis=0)[X[i, 0], :]\n",
    "    X[i, 1] = g.choice(4, p=prob)\n",
    "    for m in range(2, n):\n",
    "        prob = phi2[X[i, m-2], X[i, m-1], :]\n",
    "        X[i, m] = g.choice(4, p=prob)  # Declare X as torch tensor\n",
    "\n",
    "X = torch.from_numpy(X) # shape: (100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 3, 0, 3, 0, 3, 0, 0, 2, 1, 1, 1, 3, 3, 2, 0, 3, 2, 3, 2, 3, 1, 2,\n",
      "        0, 3, 2, 0, 3, 1, 1, 1, 1, 3, 3, 2, 0, 3, 1, 1, 0, 1, 3, 3, 2, 0, 3, 2,\n",
      "        3, 1, 2, 0, 2, 2, 0, 3, 0, 3, 2, 0, 3, 2, 0, 3, 1, 1, 3, 3, 0, 3, 2, 2,\n",
      "        0, 3, 1, 1, 3, 0, 0, 0, 3, 0, 3, 1, 2, 0, 2, 1, 1, 3, 3, 2, 3, 1, 1, 1,\n",
      "        1, 3, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "#Looking at contents of X in the sequence at batch position 1\n",
    "print(X[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the simulated dataset, we will use a SVI model in Pyro to model the background Markov model (for X[:, m]) as a neural network that takes X[:, m-2] and X[:, m-2] as inputs! Let's define the neural network, a sequential module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_NN(depth=3, width=16): # Input- (1,2,4)\n",
    "    layers = []\n",
    "    assert depth >= 0\n",
    "    layers.append(nn.Flatten())\n",
    "    if depth==0:\n",
    "        layers.append(nn.Linear(8, 4))\n",
    "    elif depth>0:\n",
    "        layers.append(nn.Linear(8, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(depth-2):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(width, 4))\n",
    "    \n",
    "    layers.append(nn.Softmax(dim=-1))\n",
    "    return nn.Sequential(*layers) #Output- (4,)\n",
    "\n",
    "markov_nn = Generate_NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    MarkovNN = pyro.module(\"Neural Markov Model\", markov_nn)\n",
    "    X_oh = nn.functional.one_hot(X, 4).float() #type: ignore\n",
    "    # One hot categorical encoding of the sequences\n",
    "    X_oh = torch.concat([torch.zeros(50, 2, 4), X_oh], dim=1).float()\n",
    "    # Padding each sequence with zeros in the beginning for unbiased Merkov\n",
    "    # estimation\n",
    "    for u in pyro.markov(range(X.shape[1]), history=2): #type:ignore\n",
    "        probs = MarkovNN(torch.concat([X_oh[:, u, :], X_oh[:, u+1, :]], dim=1))\n",
    "        # We make a vectorized plate over the batch dimension\n",
    "        with pyro.plate(\"Batch\"):\n",
    "            pyro.sample(\"X_{}\".format(u), dist.Categorical(probs), obs=X[:, u]) #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no (random) latent variables defined in the function, there's the guide function in empty. The opimizer's job will be to optimize the neural network's weights in the model alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An empty guide function\n",
    "def guide(X):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the parameters of the neural network defined inside model function using a simple ELBO loss. The model is reparameterizable since there are no latent variables defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, steps=10):\n",
    "    # Clear out other trainable parameters in the current REPL/ipython kernel\n",
    "    # session\n",
    "    pyro.clear_param_store()\n",
    "    opt = torch.optim.Adam\n",
    "    scheduler = optim.StepLR({\"optimizer\": opt, \"step_size\": 2000, \"gamma\": 0.2, #type: ignore\n",
    "                              \"optim_args\": {\"lr\": 0.001, \"betas\": (0.9, 0.999)}})\n",
    "    svi = SVI(model, guide, scheduler, loss=Trace_ELBO())\n",
    "    \n",
    "    for k in range(steps):\n",
    "        svi.step(data)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X, 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify how well the neural network has encoded the background Markov model. So we'll verify how well the netowrk recovers the conditional variable phi by training on the dataset X (which was generated using phi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll generate a dataframe that encodes various such conditional probabilies derived from markov_nn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[0,0], [0,1], [0,2], [0,3],\n",
    "                       [1,0], [1,1], [1,2], [1,3],\n",
    "                       [2,0], [2,1], [2,2], [2,3],\n",
    "                       [3,0], [3,1], [3,2], [3,3]]) # shape: (16,2)\n",
    "inputs = nn.functional.one_hot(inputs).float() #type: ignore\n",
    "out = markov_nn(inputs).detach().numpy() # (16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['(0, 0)', '(0, 1)', '(0, 2)', '(0, 3)',\n",
    "        '(1, 0)', '(1, 1)', '(1, 2)', '(1, 3)',\n",
    "        '(2, 0)', '(2, 1)', '(2, 2)', '(2, 3)',\n",
    "        '(3, 0)', '(3, 1)', '(3, 2)', '(3, 3)']\n",
    "\n",
    "df_nn = pd.DataFrame({'Conditioned BP': rows,\n",
    "                      'P(0)': out[:, 0],\n",
    "                      'P(1)': out[:, 1],\n",
    "                      'P(2)': out[:, 2],\n",
    "                      'P(3)': out[:, 3]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conditioned BP</th>\n",
       "      <th>P(0)</th>\n",
       "      <th>P(1)</th>\n",
       "      <th>P(2)</th>\n",
       "      <th>P(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0.137307</td>\n",
       "      <td>0.296920</td>\n",
       "      <td>0.246492</td>\n",
       "      <td>0.319281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.025741</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.762165</td>\n",
       "      <td>0.199254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0.044388</td>\n",
       "      <td>0.490052</td>\n",
       "      <td>0.264570</td>\n",
       "      <td>0.200990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>0.203108</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.404627</td>\n",
       "      <td>0.084443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0.099135</td>\n",
       "      <td>0.739707</td>\n",
       "      <td>0.040597</td>\n",
       "      <td>0.120561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.217215</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.094421</td>\n",
       "      <td>0.479380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.050279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.033181</td>\n",
       "      <td>0.129096</td>\n",
       "      <td>0.224584</td>\n",
       "      <td>0.613138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>0.064364</td>\n",
       "      <td>0.194463</td>\n",
       "      <td>0.099152</td>\n",
       "      <td>0.642021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>0.242307</td>\n",
       "      <td>0.684129</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.036511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.528631</td>\n",
       "      <td>0.147574</td>\n",
       "      <td>0.195212</td>\n",
       "      <td>0.128583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.317665</td>\n",
       "      <td>0.199876</td>\n",
       "      <td>0.431323</td>\n",
       "      <td>0.051136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>0.374703</td>\n",
       "      <td>0.043877</td>\n",
       "      <td>0.150777</td>\n",
       "      <td>0.430643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>0.178758</td>\n",
       "      <td>0.335816</td>\n",
       "      <td>0.401523</td>\n",
       "      <td>0.083903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.458132</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.310981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.152305</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.717582</td>\n",
       "      <td>0.116635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conditioned BP      P(0)      P(1)      P(2)      P(3)\n",
       "0          (0, 0)  0.137307  0.296920  0.246492  0.319281\n",
       "1          (0, 1)  0.025741  0.012840  0.762165  0.199254\n",
       "2          (0, 2)  0.044388  0.490052  0.264570  0.200990\n",
       "3          (0, 3)  0.203108  0.307822  0.404627  0.084443\n",
       "4          (1, 0)  0.099135  0.739707  0.040597  0.120561\n",
       "5          (1, 1)  0.217215  0.208984  0.094421  0.479380\n",
       "6          (1, 2)  0.886130  0.055619  0.007972  0.050279\n",
       "7          (1, 3)  0.033181  0.129096  0.224584  0.613138\n",
       "8          (2, 0)  0.064364  0.194463  0.099152  0.642021\n",
       "9          (2, 1)  0.242307  0.684129  0.037053  0.036511\n",
       "10         (2, 2)  0.528631  0.147574  0.195212  0.128583\n",
       "11         (2, 3)  0.317665  0.199876  0.431323  0.051136\n",
       "12         (3, 0)  0.374703  0.043877  0.150777  0.430643\n",
       "13         (3, 1)  0.178758  0.335816  0.401523  0.083903\n",
       "14         (3, 2)  0.458132  0.013854  0.217033  0.310981\n",
       "15         (3, 3)  0.152305  0.013478  0.717582  0.116635"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also tabulate phi (once again), to compare with the neural network-generated values above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conditioned BP</th>\n",
       "      <th>P(0)</th>\n",
       "      <th>P(1)</th>\n",
       "      <th>P(2)</th>\n",
       "      <th>P(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>0.265847</td>\n",
       "      <td>0.278432</td>\n",
       "      <td>0.353446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.213438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.469061</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.212499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>0.190408</td>\n",
       "      <td>0.320309</td>\n",
       "      <td>0.394577</td>\n",
       "      <td>0.094706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0.130510</td>\n",
       "      <td>0.691025</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.119028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.182082</td>\n",
       "      <td>0.208129</td>\n",
       "      <td>0.075353</td>\n",
       "      <td>0.534436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.893628</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.049326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.027103</td>\n",
       "      <td>0.150291</td>\n",
       "      <td>0.240775</td>\n",
       "      <td>0.581830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>0.066440</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.099284</td>\n",
       "      <td>0.643416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>0.258359</td>\n",
       "      <td>0.673523</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>0.028271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>0.125745</td>\n",
       "      <td>0.201966</td>\n",
       "      <td>0.120524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.289173</td>\n",
       "      <td>0.247635</td>\n",
       "      <td>0.401082</td>\n",
       "      <td>0.062109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>0.354409</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.175206</td>\n",
       "      <td>0.430860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.352572</td>\n",
       "      <td>0.378530</td>\n",
       "      <td>0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.203156</td>\n",
       "      <td>0.307503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.099723</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>0.098356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conditioned BP      P(0)      P(1)      P(2)      P(3)\n",
       "0          (0, 0)  0.102274  0.265847  0.278432  0.353446\n",
       "1          (0, 1)  0.035241  0.013038  0.738283  0.213438\n",
       "2          (0, 2)  0.068244  0.469061  0.250197  0.212499\n",
       "3          (0, 3)  0.190408  0.320309  0.394577  0.094706\n",
       "4          (1, 0)  0.130510  0.691025  0.059438  0.119028\n",
       "5          (1, 1)  0.182082  0.208129  0.075353  0.534436\n",
       "6          (1, 2)  0.893628  0.052813  0.004233  0.049326\n",
       "7          (1, 3)  0.027103  0.150291  0.240775  0.581830\n",
       "8          (2, 0)  0.066440  0.190860  0.099284  0.643416\n",
       "9          (2, 1)  0.258359  0.673523  0.039847  0.028271\n",
       "10         (2, 2)  0.551765  0.125745  0.201966  0.120524\n",
       "11         (2, 3)  0.289173  0.247635  0.401082  0.062109\n",
       "12         (3, 0)  0.354409  0.039524  0.175206  0.430860\n",
       "13         (3, 1)  0.181983  0.352572  0.378530  0.086914\n",
       "14         (3, 2)  0.475099  0.014243  0.203156  0.307503\n",
       "15         (3, 3)  0.099723  0.016313  0.785607  0.098356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's a rough agreement between the two datasets df_nn and df_phi. We'll try to improve the accuracy of predictions by subsampling on a larger dataset X in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(markov_nn.state_dict(), \"saved_nn.pt\")\n",
    "torch.save(phi, \"saved_phi.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a discrepancy so far in that we chose the batch size to be small at 50 and repeatedly used the same data X in *every* training step! This is more like a global training than batchwise, which is actually the preferred way to train neural networks. So we will use a larger number of sequences for simulated the entire dataset (say 1000) and subsample a batch every time the model function is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pyro\n",
    "from pyro import distributions as dist\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_NN(depth=3, width=16):\n",
    "    layers = []\n",
    "    assert depth >= 0\n",
    "    layers.append(nn.Flatten())\n",
    "    if depth == 0:\n",
    "        layers.append(nn.Linear(8, 4))\n",
    "    elif depth > 0:\n",
    "        layers.append(nn.Linear(8, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(depth-2):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(width, 4))\n",
    "\n",
    "    layers.append(nn.Softmax(dim=-1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "markov_nn = Generate_NN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the saved values of trained model (not extremely vital- one can simply use an untrained model too, without much loss!) from the previous section and the variable phi (that contains the conditional probabilities):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_nn.load_state_dict(torch.load(\"saved_nn.pt\"))\n",
    "phi = torch.load(\"saved_phi.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate a larger DNA dataset X more sequences inside a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1000\n",
    "n = 100\n",
    "\n",
    "X = np.empty((batch, n), dtype=int)\n",
    "g = np.random.default_rng()\n",
    "phi2 = phi.numpy()  # Converted to NumPy array\n",
    "\n",
    "for i in range(batch):\n",
    "    prob = np.mean(phi2, axis=(0, 1))\n",
    "    X[i, 0] = g.choice(4, p=prob)  # Marginalizing for positions 1,2\n",
    "    prob = np.mean(phi2, axis=0)[X[i, 0], :]\n",
    "    X[i, 1] = g.choice(4, p=prob)\n",
    "    for m in range(2, n):\n",
    "        prob = phi2[X[i, m-2], X[i, m-1], :]\n",
    "        X[i, m] = g.choice(4, p=prob)\n",
    "\n",
    "X = torch.from_numpy(X)  # Declare X as torch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll redefine the model function to sample a sub-batch (of size 50 as before) of the dataset instead of the entire dataset like we did in the previous section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    MarkovNN = pyro.module(\"Neural Markov Model\", markov_nn)\n",
    "    with pyro.plate(\"Batch\", size=1000, subsample_size=50) as ind:\n",
    "    # This randomly selects 50 indices among the 1000 possible ones\n",
    "        X_oh = nn.functional.one_hot(X, 4).float().index_select(0, ind) #type: ignore\n",
    "        # One hot categorical encoding of the sequences\n",
    "        X_oh = torch.concat([torch.zeros(50, 2, 4), X_oh], dim=1).float()\n",
    "        # Padding each sequence with zeros in the beginning for unbiased Merkov\n",
    "        # estimation\n",
    "        for u in pyro.markov(range(X.shape[1]), history=2): #type:ignore\n",
    "            probs = MarkovNN(torch.concat([X_oh[:, u, :], X_oh[:, u+1, :]], dim=1))\n",
    "            pyro.sample(\"X_{}\".format(u), dist.Categorical(probs),  # type: ignore\n",
    "                        obs=X.index_select(0, ind)[:, u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as an empty guide function and the usual train function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(X):\n",
    "    pass\n",
    "\n",
    "def train(data, steps=10):\n",
    "    # Clear out other trainable parameters in the current REPL/ipython kernel\n",
    "    # session\n",
    "    pyro.clear_param_store()\n",
    "    opt = torch.optim.Adam\n",
    "    scheduler = optim.StepLR({\"optimizer\": opt, \"step_size\": 1000, \"gamma\": 0.2,  # type: ignore\n",
    "                              \"optim_args\": {\"lr\": 0.001, \"betas\": (0.9, 0.999)}})\n",
    "    svi = SVI(model, guide, scheduler, loss=Trace_ELBO())\n",
    "\n",
    "    for k in range(steps):\n",
    "        svi.step(data)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X, 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and display dataframes for phi and markov_nn for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['(0, 0)', '(0, 1)', '(0, 2)', '(0, 3)',\n",
    "        '(1, 0)', '(1, 1)', '(1, 2)', '(1, 3)',\n",
    "        '(2, 0)', '(2, 1)', '(2, 2)', '(2, 3)',\n",
    "        '(3, 0)', '(3, 1)', '(3, 2)', '(3, 3)']\n",
    "\n",
    "flat_phi = np.reshape(phi, [-1, 4])\n",
    "\n",
    "df_phi = pd.DataFrame({'Conditioned BP': rows,\n",
    "                       'P(0)': flat_phi[:, 0],\n",
    "                       'P(1)': flat_phi[:, 1],\n",
    "                       'P(2)': flat_phi[:, 2],\n",
    "                       'P(3)': flat_phi[:, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3],\n",
    "                       [1, 0], [1, 1], [1, 2], [1, 3],\n",
    "                       [2, 0], [2, 1], [2, 2], [2, 3],\n",
    "                       [3, 0], [3, 1], [3, 2], [3, 3]])\n",
    "inputs = nn.functional.one_hot(inputs).float()  # type: ignore\n",
    "out = markov_nn(inputs).detach().numpy()\n",
    "\n",
    "df_nn = pd.DataFrame({'Conditioned BP': rows,\n",
    "                      'P(0)': out[:, 0],\n",
    "                      'P(1)': out[:, 1],\n",
    "                      'P(2)': out[:, 2],\n",
    "                      'P(3)': out[:, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conditioned BP</th>\n",
       "      <th>P(0)</th>\n",
       "      <th>P(1)</th>\n",
       "      <th>P(2)</th>\n",
       "      <th>P(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>0.265847</td>\n",
       "      <td>0.278432</td>\n",
       "      <td>0.353446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.213438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.469061</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.212499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>0.190408</td>\n",
       "      <td>0.320309</td>\n",
       "      <td>0.394577</td>\n",
       "      <td>0.094706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0.130510</td>\n",
       "      <td>0.691025</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>0.119028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.182082</td>\n",
       "      <td>0.208129</td>\n",
       "      <td>0.075353</td>\n",
       "      <td>0.534436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.893628</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.049326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.027103</td>\n",
       "      <td>0.150291</td>\n",
       "      <td>0.240775</td>\n",
       "      <td>0.581830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>0.066440</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.099284</td>\n",
       "      <td>0.643416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>0.258359</td>\n",
       "      <td>0.673523</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>0.028271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.551765</td>\n",
       "      <td>0.125745</td>\n",
       "      <td>0.201966</td>\n",
       "      <td>0.120524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.289173</td>\n",
       "      <td>0.247635</td>\n",
       "      <td>0.401082</td>\n",
       "      <td>0.062109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>0.354409</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.175206</td>\n",
       "      <td>0.430860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>0.181983</td>\n",
       "      <td>0.352572</td>\n",
       "      <td>0.378530</td>\n",
       "      <td>0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.203156</td>\n",
       "      <td>0.307503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.099723</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>0.098356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conditioned BP      P(0)      P(1)      P(2)      P(3)\n",
       "0          (0, 0)  0.102274  0.265847  0.278432  0.353446\n",
       "1          (0, 1)  0.035241  0.013038  0.738283  0.213438\n",
       "2          (0, 2)  0.068244  0.469061  0.250197  0.212499\n",
       "3          (0, 3)  0.190408  0.320309  0.394577  0.094706\n",
       "4          (1, 0)  0.130510  0.691025  0.059438  0.119028\n",
       "5          (1, 1)  0.182082  0.208129  0.075353  0.534436\n",
       "6          (1, 2)  0.893628  0.052813  0.004233  0.049326\n",
       "7          (1, 3)  0.027103  0.150291  0.240775  0.581830\n",
       "8          (2, 0)  0.066440  0.190860  0.099284  0.643416\n",
       "9          (2, 1)  0.258359  0.673523  0.039847  0.028271\n",
       "10         (2, 2)  0.551765  0.125745  0.201966  0.120524\n",
       "11         (2, 3)  0.289173  0.247635  0.401082  0.062109\n",
       "12         (3, 0)  0.354409  0.039524  0.175206  0.430860\n",
       "13         (3, 1)  0.181983  0.352572  0.378530  0.086914\n",
       "14         (3, 2)  0.475099  0.014243  0.203156  0.307503\n",
       "15         (3, 3)  0.099723  0.016313  0.785607  0.098356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural generated values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conditioned BP</th>\n",
       "      <th>P(0)</th>\n",
       "      <th>P(1)</th>\n",
       "      <th>P(2)</th>\n",
       "      <th>P(3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0.100088</td>\n",
       "      <td>0.275475</td>\n",
       "      <td>0.273854</td>\n",
       "      <td>0.350582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.742448</td>\n",
       "      <td>0.211458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0.064053</td>\n",
       "      <td>0.483263</td>\n",
       "      <td>0.227968</td>\n",
       "      <td>0.224715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>0.185822</td>\n",
       "      <td>0.319798</td>\n",
       "      <td>0.398659</td>\n",
       "      <td>0.095720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0.127749</td>\n",
       "      <td>0.696895</td>\n",
       "      <td>0.056626</td>\n",
       "      <td>0.118730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.188077</td>\n",
       "      <td>0.214259</td>\n",
       "      <td>0.066473</td>\n",
       "      <td>0.531191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.891609</td>\n",
       "      <td>0.055109</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.046811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.158575</td>\n",
       "      <td>0.234166</td>\n",
       "      <td>0.581619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.100325</td>\n",
       "      <td>0.641739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>0.263053</td>\n",
       "      <td>0.666568</td>\n",
       "      <td>0.036034</td>\n",
       "      <td>0.034345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.559792</td>\n",
       "      <td>0.123888</td>\n",
       "      <td>0.197153</td>\n",
       "      <td>0.119167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.288555</td>\n",
       "      <td>0.250828</td>\n",
       "      <td>0.405128</td>\n",
       "      <td>0.055489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>0.345077</td>\n",
       "      <td>0.040812</td>\n",
       "      <td>0.177540</td>\n",
       "      <td>0.436571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>0.184828</td>\n",
       "      <td>0.349928</td>\n",
       "      <td>0.373680</td>\n",
       "      <td>0.091564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(3, 2)</td>\n",
       "      <td>0.470573</td>\n",
       "      <td>0.016186</td>\n",
       "      <td>0.206435</td>\n",
       "      <td>0.306806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.102486</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>0.778460</td>\n",
       "      <td>0.101150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conditioned BP      P(0)      P(1)      P(2)      P(3)\n",
       "0          (0, 0)  0.100088  0.275475  0.273854  0.350582\n",
       "1          (0, 1)  0.032123  0.013971  0.742448  0.211458\n",
       "2          (0, 2)  0.064053  0.483263  0.227968  0.224715\n",
       "3          (0, 3)  0.185822  0.319798  0.398659  0.095720\n",
       "4          (1, 0)  0.127749  0.696895  0.056626  0.118730\n",
       "5          (1, 1)  0.188077  0.214259  0.066473  0.531191\n",
       "6          (1, 2)  0.891609  0.055109  0.006471  0.046811\n",
       "7          (1, 3)  0.025640  0.158575  0.234166  0.581619\n",
       "8          (2, 0)  0.063732  0.194204  0.100325  0.641739\n",
       "9          (2, 1)  0.263053  0.666568  0.036034  0.034345\n",
       "10         (2, 2)  0.559792  0.123888  0.197153  0.119167\n",
       "11         (2, 3)  0.288555  0.250828  0.405128  0.055489\n",
       "12         (3, 0)  0.345077  0.040812  0.177540  0.436571\n",
       "13         (3, 1)  0.184828  0.349928  0.373680  0.091564\n",
       "14         (3, 2)  0.470573  0.016186  0.206435  0.306806\n",
       "15         (3, 3)  0.102486  0.017904  0.778460  0.101150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Phi values')\n",
    "display(df_phi)\n",
    "print('Neural generated values')\n",
    "display(df_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b08fbbdb625a1bd47f2df3b9a6d08aa77f5ee8b60b707c6c4c23898f6e322d6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pyro-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
