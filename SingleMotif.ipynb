{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskRCNN-based model for motif identification\n",
    "\n",
    "We assume $n=1000$ input sequences $X$ (of length $l=100$) containing one motif each and each motif has one to one correspondence with a module. We assume a total of $r=3$ modules and each sequence has a module identity $I$. We model the motifs as position weight matrices (PWMs) whose widths $w$ are bounded above by a particular value (20). The starting postion of each motif is represented by $Z$ and with the (obvious) constraint: $0 < Z < n-l$. The background DNA in each sequence that do not belong to any sequence are *assumed* to follow a (second order) Markov probability model (the probability of given BP inside X is conditioned on the the values of 2 BPs that appear before it, $P(X_u = B_1) = \\phi(B_1|X_{u-2}, X_{u-1})$. The support of base pair values $(B)$ is the set: $\\text{range}(4)$.\n",
    "\n",
    "Let's first import necessary libraries and define some global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from scipy import integrate, special\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, TraceGraph_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "batch = 50 #Minibatch for sub-sampling\n",
    "l = 100\n",
    "r = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write some code to simulate our input data X. For that we need to fix some ground-truth values of various latent variables. Later when we define and train an SVI (stochastic variational inference) based model on the generated X, a good model is expected to reproduce these ground truth values (names end with $0$ as a convention). So let's get to it!\n",
    "\n",
    "First we generate some ground truth values of latent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "prior = dist.Dirichlet(torch.ones([4, 4, 4]))  # type: ignore\n",
    "# Distribution from which Markov probabilities will be drawn from\n",
    "phi0 = prior.sample()\n",
    "print(phi0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of $[4,4,4]$ reflects the conditional probability on a support set of size 4, over two similar variables whose support is $[4]$ each, resulting in the given array size.\n",
    "\n",
    "Now, we will sample motif widths $w$ and their pwm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 3, 2, 2, 3, 0, 3, 0, 3, 2, 1, 0, 2, 3, 1, 3, 0, 0, 1],\n",
      "        [3, 1, 2, 1, 0, 0, 3, 0, 2, 2, 1, 0, 2, 1, 2, 1, 3, 3, 2, 3],\n",
      "        [3, 1, 3, 1, 3, 2, 0, 3, 1, 0, 2, 0, 3, 1, 1, 1, 3, 1, 3, 0]])\n"
     ]
    }
   ],
   "source": [
    "w0 = torch.randint(5, 20, size=(r,))\n",
    "d = dist.Categorical(torch.full([4], 0.25))\n",
    "pwm0 = d.sample([r, 20])\n",
    "print(pwm0)\n",
    "# The actual pwm are slices determined by w\n",
    "# not the whole sequences of width 20 each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate module identities $I$ and motif starting positions $Z$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = dist.Dirichlet(torch.full([n, r], 4.)).sample()\n",
    "d = dist.Categorical(prob)\n",
    "I0 = d.sample()\n",
    "I0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65, 42, 37, 24, 26, 60, 53, 29, 45, 48, 47, 39, 40, 28, 42, 45, 48, 33,\n",
       "        13, 62, 61, 71, 54, 52, 55, 30, 40, 42, 11, 61, 30, 56, 20, 45, 38, 55,\n",
       "        37, 61, 65, 48, 22, 16, 49, 32, 25, 22, 56, 52, 59, 67, 53, 52, 41, 55,\n",
       "        65, 74, 37, 39, 58, 66, 33, 63, 42, 17, 58, 59, 19, 40, 32, 57, 38, 58,\n",
       "        40, 50, 51,  8, 66, 69, 56, 46, 28, 44, 34, 66, 61, 32, 55, 27, 37, 50,\n",
       "        78, 40, 60, 46, 34, 53, 50, 71, 22, 49], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z0 = torch.empty([n], dtype=torch.int32)\n",
    "d = dist.Beta(4., 4.)\n",
    "\n",
    "for i in range(n):\n",
    "    num = d.sample()\n",
    "    num = num*(l-w0[I0[i]])\n",
    "    Z0[i] = num.round().int()\n",
    "    \n",
    "Z0[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ground truth values generated, we will generate the input data $X$. Remember that only this $X$ will be fed to the SVI model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.empty([n, l], dtype=torch.int32)\n",
    "\n",
    "for i in range(n):\n",
    "    prob = torch.mean(phi0, (0, 1))\n",
    "    X[i, 0] = dist.Categorical(prob).sample()\n",
    "    prob = torch.mean(phi0, dim=0)[X[i, 0], :]\n",
    "    X[i, 1] = dist.Categorical(prob).sample()\n",
    "\n",
    "    for u in range(2, Z0[i]):  # Markov sampling for bg DNA\n",
    "        prob = phi0[X[i, u-2], X[i, u-1], :]\n",
    "        X[i, u] = dist.Categorical(prob).sample()\n",
    "\n",
    "    X[i, Z0[i]:Z0[i]+w0[I0[i]]] = pwm0[I0[i], :w0[I0[i]]]  # Motif at pos Z[i]\n",
    "\n",
    "    for u in range(Z0[i]+w0[I0[i]], l):  # Markov sampling for bg DNA\n",
    "        prob = phi0[X[i, u-2], X[i, u-1], :]\n",
    "        X[i, u] = dist.Categorical(prob).sample()\n",
    "        \n",
    "X = X.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 1, 1, 1, 1, 1, 1, 0, 3, 0, 3, 1, 1, 2, 3, 2, 2, 1, 0, 0, 2, 1, 0,\n",
       "         3, 1, 0, 3, 0, 1, 0, 3, 0, 3, 1, 3, 3, 0, 2, 1, 0, 1, 3, 1, 3, 1, 3, 2,\n",
       "         0, 3, 1, 0, 2, 0, 3, 1, 1, 1, 3, 1, 3, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 3,\n",
       "         1, 0, 1, 3, 1, 0, 1, 2, 3, 2, 3, 2, 1, 0, 3, 0, 1, 2, 3, 2, 2, 1, 0, 2,\n",
       "         1, 0, 0, 1]),\n",
       " tensor(42, dtype=torch.int32),\n",
       " tensor(19))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], Z0[1], w0[I0[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pwm0, \"saved_pwm.pt\")\n",
    "torch.save(w0, \"saved_w.pt\")\n",
    "torch.save(phi0, \"saved_phi.pt\")\n",
    "torch.save(Z0, \"saved_Z.pt\")\n",
    "torch.save(I0, \"saved_I.pt\")\n",
    "torch.save(X, \"saved_X.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define custom distributions that'll be useful in the SVI model we're going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that integrates the Beta distribution's pdf\n",
    "def beta_integral(x1, x2, a: torch.Tensor, b: torch.Tensor):\n",
    "    def beta_pdf(x):\n",
    "        return (x**(a-1))*((1-x)**(b-1))/special.beta(a, b)\n",
    "    \n",
    "    return integrate.quad(beta_pdf, x1, x2)[0]\n",
    "    \n",
    "class DiscretizedBeta(dist.TorchDistribution):\n",
    "    def __init__(self, low, high, conc1, conc2):\n",
    "        self.beta = dist.Beta(conc1, conc2)\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.a = conc1.detach().numpy()\n",
    "        self.b = conc2.detach().numpy()\n",
    "        \n",
    "        prob = torch.empty(size=[high-low], dtype=torch.float32)\n",
    "        x = np.linspace(0., 1., high-low+1)\n",
    "        for i in torch.arange(high-low):\n",
    "            prob[i] = beta_integral(x[i], x[i+1], self.a, self.b)\n",
    "        \n",
    "        self.categorical = dist.Categorical(prob)\n",
    "        \n",
    "        super().__init__(self.beta.batch_shape, self.beta.event_shape,\n",
    "                         validate_args=False)\n",
    "        \n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        return self.categorical.sample(sample_shape) + self.low\n",
    "    \n",
    "    def log_prob(self, value):\n",
    "        return self.categorical.log_prob(value-self.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DiscretizedBeta(0, 10, torch.tensor(20.), torch.tensor(10.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = d.sample(torch.tensor([1000]))\n",
    "y = np.histogram(x, np.arange(x.min(), x.max()+2)-0.5)\n",
    "plt.bar(np.arange(x.min(), x.max()+0.5), y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(0, 10)\n",
    "plt.bar(x, torch.exp(d.log_prob(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force strategy\n",
    "\n",
    "Let's define a model function that assigns a prior distributions for various latent variables and samples them to generate various components of X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(low, size):\n",
    "    phi_prior = dist.Delta(torch.full([4, 4, 4], 0.25))\n",
    "    \n",
    "    with pyro.plate(\"phi loop1\", 4):\n",
    "        with pyro.plate(\"phi loop2\", 4):\n",
    "            with pyro.plate(\"phi loop3\", 4):\n",
    "                phi = pyro.sample(\"phi\", phi_prior)\n",
    "    phi_1 = torch.mean(phi, dim=0)\n",
    "    phi_0 = torch.mean(phi_1, dim=0)\n",
    "    \n",
    "    pwm_prior = dist.Delta(torch.full([r, 20, 4], 0.25))\n",
    "    with pyro.plate(\"pwm loop1\", 4):\n",
    "        with pyro.plate(\"pwm loop2\", 20):\n",
    "            with pyro.plate(\"pwm loop3\", r):\n",
    "                pwm = pyro.sample(\"pwm\", pwm_prior)\n",
    "    \n",
    "    w_prior = DiscretizedBeta(5, 20, torch.tensor(1.), \n",
    "                              torch.tensor(1.))\n",
    "    w = torch.empty([r], dtype=torch.int64)\n",
    "    for j in pyro.plate(\"w loop\", r):\n",
    "        w[torch.tensor(j)] = pyro.sample(\"w_{}\".format(j),\n",
    "                                         w_prior)\n",
    "    \n",
    "    for i in pyro.plate(\"Batch\", size):\n",
    "        i = i + low\n",
    "        \n",
    "        I_prior = dist.Categorical(logits=torch.ones([r]))\n",
    "        I = pyro.sample(\"I_{}\".format(i), I_prior)\n",
    "        \n",
    "        Z_prior = dist.Categorical(logits=torch.ones([l - w[I]]))\n",
    "        Z = pyro.sample(\"Z_{}\".format(i), Z_prior)\n",
    "        \n",
    "        for u in pyro.markov(range(l), history=2): #type: ignore\n",
    "            if u==0:\n",
    "                pyro.sample(\"X_{},0\".format(i),\n",
    "                            dist.Categorical(probs=phi_0),\n",
    "                            obs=X[i, u])\n",
    "            elif u==1:\n",
    "                pyro.sample(\"X_{},1\".format(i),\n",
    "                            dist.Categorical(probs=phi_1[X[u-1]]),\n",
    "                            obs=X[i, u])\n",
    "            elif ((u > 1) and (u < Z)) or (u > Z+w[I]):\n",
    "                pyro.sample(\"X_{},{}\".format(i, u), \n",
    "                            dist.Categorical(probs=phi[X[i,u-2], X[i,u-1]]),\n",
    "                            obs=X[i, u])\n",
    "            else:\n",
    "                pyro.sample(\"X_{},{}\".format(i, u),\n",
    "                            dist.Categorical(probs=pwm[I, u-Z]),\n",
    "                            obs=X[i, u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the guide function, we generate the (2nd order) backgorund Markov distribution $phi$ from a softmax-activated trainable parameter. We put nested \"pyro.plate\"s since the components are independent of each other. $pwm$ is also sampled similarly. The motif width $w$ is sampled from a \"DiscretizedBeta\" distribution among values in the interval $[5, 20]$. Given these latent variables, we need to find out the remaining variables $I$ and $Z$ that also happen to depend on the input data $X$. For predicting I and Z, the brute-force way is obviously elementwise-multiplying the ith pwm (sliced with w) at every possible position Z and then multiplying the remaining sequence with background distribution phi. Multiplying the elements of these probability vectors gives us a \"score\" for every possible value of the pair {I, Z}. This process becomes more and more costly as the values of l and r increase, though. So when this becomes parctically intractable, we can use estimators like neural networks to approximate this.\n",
    "\n",
    "Let's define the \"brute-force\" guide function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide_bf(low, size):\n",
    "    phi_param = pyro.param(\"phi_param\", torch.ones([4,4,4]))\n",
    "    softmax = nn.Softmax(-1)\n",
    "    d = dist.Delta(softmax(phi_param))\n",
    "    with pyro.plate(\"phi loop1\", 4):\n",
    "        with pyro.plate(\"phi loop2\", 4):\n",
    "            with pyro.plate(\"phi loop3\", 4):\n",
    "                phi = pyro.sample(\"phi\", d)\n",
    "    phi_1 = torch.mean(phi, dim=0)\n",
    "    phi_0 = torch.mean(phi_1, dim=0)\n",
    "    \n",
    "    pwm_param = pyro.param(\"pwm_param\", torch.full([r,20,4], 0.1))\n",
    "    d = dist.Dirichlet(pwm_param)\n",
    "    with pyro.plate(\"pwm loop1\", 4):\n",
    "        with pyro.plate(\"pwm loop2\", 20):\n",
    "            with pyro.plate(\"pwm loop3\", r):\n",
    "                pwm = pyro.sample(\"pwm\", d)\n",
    "    \n",
    "    w_param = pyro.param(\"w_param\", torch.ones([r, 2]))**2\n",
    "    d = [DiscretizedBeta(5, 21, w_param[j, 0], w_param[j, 1])\n",
    "         for j in range(r)]\n",
    "    w = torch.empty([r], dtype=torch.int64).detach()\n",
    "    for j in pyro.plate(\"w loop\", r):\n",
    "        w[torch.tensor(j)] = pyro.sample(\"w_{}\".format(j), d[torch.tensor(j)])\n",
    "    \n",
    "    Xoh = F.one_hot(X[low:low+size, :], 4).float()\n",
    "    \n",
    "    for i in pyro.plate(\"Batch\", size):\n",
    "        i = i + low\n",
    "        y1 = torch.empty([r]).detach()\n",
    "        y2 = []\n",
    "        # Loop over every possible I and Z\n",
    "        for j in torch.arange(r):\n",
    "            y = torch.empty((l-w[j], l)).detach()\n",
    "            for z in torch.arange(l-w[j]):\n",
    "                for u in torch.arange(z):\n",
    "                    if u == 0:\n",
    "                        y[z, u] = torch.dot(Xoh[i, u, :],\n",
    "                                            phi_0)\n",
    "                    elif u == 1:\n",
    "                        y[z, 1] = torch.dot(Xoh[i, u, :],\n",
    "                                            phi_1[0, :])\n",
    "                    else:\n",
    "                        y[z, u] = torch.dot(Xoh[i, u, :], \n",
    "                                        phi[X[i, u-2], X[i, u-1], :])\n",
    "                        \n",
    "                for u in torch.arange(z, z+w[j]):\n",
    "                    y[z, u] = torch.dot(Xoh[i, u, :],\n",
    "                                        pwm[j, u-z, :])\n",
    "                for u in torch.arange(z+w[j], l):\n",
    "                    y[z, u] = torch.dot(Xoh[i, u, :],\n",
    "                                        phi[X[i, u-2], X[i, u-1], :])\n",
    "            y = torch.log(y)\n",
    "            y2.append(y)\n",
    "            y = torch.sum(y, 1)\n",
    "            y1[j] = torch.logsumexp(y, 0)\n",
    "        I = pyro.sample(\"I_{}\".format(i), dist.Categorical(logits=y1))\n",
    "        \n",
    "        pyro.sample(\"Z_{}\".format(i), dist.Categorical(logits=y2[I]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bf(epochs=10, batch_size=100):\n",
    "    # Clear out other trainable parameters in the current REPL/ipython kernel\n",
    "    # session\n",
    "    pyro.clear_param_store()\n",
    "    opt = torch.optim.Adam\n",
    "    scheduler = optim.StepLR({\"optimizer\": opt, \"step_size\": 250, \"gamma\": 0.2,  # type: ignore\n",
    "                              \"optim_args\": {\"lr\": 0.001, \"betas\": (0.9, 0.999)}})\n",
    "    svi = SVI(model, guide_bf, scheduler, loss=Trace_ELBO())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        steps_per_epoch = n//batch_size\n",
    "        low = 0\n",
    "        for step in range(steps_per_epoch):\n",
    "            svi.step(low, batch_size)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_bf(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a lot of reasons, the \"brute force\" guide function doesn't seem to be viable (and it crashed my laptop's RAM). For example, calculating the ELBO loss involves averaging over samples of latent variables $z$ (wrt the guide function) a large number of times. Also, log probabilities of these predictioned must be tracked too. So when the guide function makes a calculation of size $O(\\text{batchsize}*l^2*r)$ in order to predict $I$ and $Z$, we were all seeing it here. Moreover, multiplying together $l=100$ number of probabilities won't be numerically stable enough for gradients wrt to the parameters defined inside the guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain neural strategy\n",
    "\n",
    "This means we need a different guide function which is a lot more cheaper to evaluate and numerically stable. Since we tracked these problems to the part where we sampled $I$ and $Z$ in guide_bf, we'll build a neural network that takes X as input and outputs certain distribution parameters associated with the latent variables $I$ and $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neural network that outputs categorical params of I\n",
    "# and Delta center of Z. Some RPN inspiration seems neccessary!\n",
    "class MotifCNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv1d(4, 16, 5, padding='valid'), # l=96\n",
    "            nn.Mish(),\n",
    "            nn.MaxPool1d(2), # l=48\n",
    "            nn.Conv1d(16, 16, 5, padding='valid'), # l=44\n",
    "            nn.Mish(),\n",
    "            nn.MaxPool1d(2), # l=22\n",
    "            nn.Conv1d(16, 16, 3, padding='valid'), # l=20\n",
    "            nn.Mish(),\n",
    "            nn.MaxPool1d(2) # l=10\n",
    "        )\n",
    "        self.I_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(10*16, 32),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(32, r),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.shared_conv = nn.Conv1d(16, r, 3, padding='same')\n",
    "        self.prob_conv = nn.Conv1d(1, 1, 1)\n",
    "        self.delta_conv = nn.Conv1d(1, 1, 1)\n",
    "    \n",
    "    def predict_I(self, x: torch.Tensor):\n",
    "        x = self.backbone(x)\n",
    "        return self.I_head(x)\n",
    "        \n",
    "    def predict_Z(self, x: torch.Tensor, I: torch.Tensor):\n",
    "        x = self.backbone(x)\n",
    "        shared = self.shared_conv(x)[:, I:I+1, :]\n",
    "        shared = F.mish(shared)\n",
    "        \n",
    "        probs = self.prob_conv(shared)\n",
    "        probs = torch.squeeze(F.softmax(probs, -1))\n",
    "        \n",
    "        deltas = self.delta_conv(shared)\n",
    "        deltas = torch.squeeze(torch.sigmoid(deltas))\n",
    "        \n",
    "        return probs, deltas\n",
    "    \n",
    "\n",
    "motif_cnn = MotifCNN()\n",
    "motif_cnn = pyro.module(\"Motif CNN\", motif_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplacedCategorical(dist.TorchDistribution):\n",
    "    def __init__(self, probs, interval):\n",
    "        self.interval = interval\n",
    "        self.categorical = dist.Categorical(probs)\n",
    "        super().__init__(self.categorical.batch_shape,\n",
    "                         self.categorical.event_shape,\n",
    "                         validate_args=False)\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        return self.interval[self.categorical.sample(sample_shape)]\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        def f(v):\n",
    "            if v in self.interval:\n",
    "                return torch.where(self.interval==v)[0][0]\n",
    "            else:\n",
    "                return torch.tensor(-1)\n",
    "        \n",
    "        return self.categorical.log_prob(f(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(low, size):\n",
    "    phi_prior = dist.Delta(torch.full([4, 4, 4], 0.25))\n",
    "    \n",
    "    with pyro.plate(\"phi loop1\", 4):\n",
    "        with pyro.plate(\"phi loop2\", 4):\n",
    "            with pyro.plate(\"phi loop3\", 4):\n",
    "                phi = pyro.sample(\"phi\", phi_prior)\n",
    "    phi_1 = torch.mean(phi, dim=0)\n",
    "    phi_0 = torch.mean(phi_1, dim=0)\n",
    "    \n",
    "    pwm_prior = dist.Dirichlet(torch.full([r, 20, 4], 0.1))\n",
    "    with pyro.plate(\"pwm loop2\", 20):\n",
    "        with pyro.plate(\"pwm loop3\", r):\n",
    "            pwm = pyro.sample(\"pwm\", pwm_prior)\n",
    "    \n",
    "    w_prior = DiscretizedBeta(5, 21, torch.tensor(1.), \n",
    "                              torch.tensor(1.))\n",
    "    w = torch.empty([r], dtype=torch.int64)\n",
    "    for j in pyro.plate(\"w loop\", r):\n",
    "        w[torch.tensor(j)] = pyro.sample(\"w_{}\".format(j),\n",
    "                                         w_prior)\n",
    "    \n",
    "    I_prior = dist.Categorical(logits=torch.ones([size,r]))\n",
    "    with pyro.plate(\"I loop\", size):\n",
    "        I = pyro.sample(\"I_{}:{}\".format(low, low+size), \n",
    "                        I_prior)\n",
    "    \n",
    "    for i in pyro.plate(\"Z loop\", size):\n",
    "        i = i + low\n",
    "        \n",
    "        Z_prior = dist.Categorical(logits=torch.ones([l - w[I[i-low]]]))\n",
    "        Z = pyro.sample(\"Z_{}\".format(i), Z_prior)\n",
    "        \n",
    "        for u in pyro.markov(range(l), history=2): #type: ignore\n",
    "            if u==0 and Z>0:\n",
    "                pyro.sample(\"X_{},0\".format(i),\n",
    "                            dist.Categorical(probs=phi_0),\n",
    "                            obs=X[i, u])\n",
    "            elif u==1 and Z>1:\n",
    "                pyro.sample(\"X_{},1\".format(i),\n",
    "                            dist.Categorical(probs=phi_1[X[i,0]]),\n",
    "                            obs=X[i, u])\n",
    "            elif ((u > 1) and (u < Z)) or (u >= Z+w[I[i-low]]):\n",
    "                pyro.sample(\"X_{},{}\".format(i, u), \n",
    "                            dist.Categorical(probs=phi[X[i,u-2], X[i,u-1]]),\n",
    "                            obs=X[i, u])\n",
    "            elif (u >= Z) and (u < Z+w[I[i-low]]):\n",
    "                pyro.sample(\"X_{},{}\".format(i, u),\n",
    "                            dist.Categorical(probs=pwm[I[i-low], u-Z]),\n",
    "                            obs=X[i, u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the neural network-enabled guide function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 4, 100])\n",
      "torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "def guide_neural1(low, size):\n",
    "    phi_param = pyro.param(\"phi_param\", torch.ones([4, 4, 4]))\n",
    "    softmax = nn.Softmax(-1)\n",
    "    d = dist.Delta(softmax(phi_param))\n",
    "    with pyro.plate(\"phi loop1\", 4):\n",
    "        with pyro.plate(\"phi loop2\", 4):\n",
    "            with pyro.plate(\"phi loop3\", 4):\n",
    "                phi = pyro.sample(\"phi\", d)\n",
    "\n",
    "    pwm_param = pyro.param(\"pwm_param\", torch.full([r, 20, 4], 0.1))\n",
    "    d = dist.Dirichlet(pwm_param)\n",
    "    with pyro.plate(\"pwm loop2\", 20):\n",
    "        with pyro.plate(\"pwm loop3\", r):\n",
    "            pwm = pyro.sample(\"pwm\", d)\n",
    "\n",
    "    w_param = pyro.param(\"w_param\", torch.ones([r, 2]))**2\n",
    "    d = [DiscretizedBeta(5, 21, w_param[j, 0], w_param[j, 1])\n",
    "         for j in range(r)]\n",
    "    w = torch.empty([r], dtype=torch.int64)\n",
    "    for j in pyro.plate(\"w loop\", r):\n",
    "        w[torch.tensor(j)] = pyro.sample(\"w_{}\".format(j), d[torch.tensor(j)])\n",
    "    \n",
    "    Xoh = F.one_hot(X[low:low+size, :], 4).float()\n",
    "    Xoh = torch.permute(Xoh, (0,2,1))\n",
    "    print(Xoh.shape)\n",
    "    \n",
    "    params = motif_cnn.predict_I(Xoh)\n",
    "    d = dist.Categorical(params)\n",
    "    with pyro.plate(\"I loop\", size):\n",
    "        I = pyro.sample(\"I_{}:{}\".format(low, low+size), d)\n",
    "    \n",
    "    for i in pyro.plate(\"Z loop\", size):\n",
    "        i = i + torch.tensor(0)\n",
    "        y = Xoh[i:i+1, :, :]\n",
    "        \n",
    "        if i==0:\n",
    "            print(y.shape)\n",
    "        \n",
    "        probs, deltas = motif_cnn.predict_Z(y, I[i])\n",
    "        \n",
    "        interval = torch.linspace(0, l-w[I[i]],\n",
    "                                  probs.shape[0]+1)[:-1]\n",
    "        spacing = interval[1]-interval[0]\n",
    "        interval = torch.round(interval + (spacing*deltas)).long()\n",
    "        d = DisplacedCategorical(probs, interval)\n",
    "        pyro.sample(\"Z_{}\".format(i+low), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural1(epochs=10, batch_size=100):\n",
    "    # Clear out other trainable parameters in the current REPL/ipython kernel\n",
    "    # session\n",
    "    pyro.clear_param_store()\n",
    "    opt = torch.optim.Adam\n",
    "    scheduler = optim.StepLR({\"optimizer\": opt, \"step_size\": 50, \"gamma\": 0.2,  # type: ignore\n",
    "                              \"optim_args\": {\"lr\": 0.01, \"betas\": (0.9, 0.999)}})\n",
    "    svi = SVI(model2, guide_neural1, scheduler, loss=Trace_ELBO())\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "        steps_per_epoch = n//batch_size\n",
    "        low = 0\n",
    "        for step in range(steps_per_epoch):\n",
    "            svi.step(low, batch_size)\n",
    "            low = low + batch_size\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee2384d682342609d5cfc16c55f90db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_neural1(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = pyro.get_param_store()\n",
    "param_dict.save(\"saved_param_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(motif_cnn.state_dict(), \"motif_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how well the trained model infers the values of ground truth latent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict.load(\"saved_param_dict.pt\")\n",
    "motif_cnn = MotifCNN()\n",
    "motif_cnn = pyro.module(\"Motif CNN\", motif_cnn)\n",
    "motif_cnn.load_state_dict(torch.load(\"motif_cnn.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi0 = torch.load(\"saved_phi.pt\")\n",
    "pwm0 = torch.load(\"saved_pwm.pt\")\n",
    "w0 = torch.load(\"saved_w.pt\")\n",
    "I0 = torch.load(\"saved_I.pt\")\n",
    "Z0 = torch.load(\"saved_Z.pt\")\n",
    "X = torch.load(\"saved_X.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the learned latent variables using the associated variational parameters or neural networks. Let's get some of them this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1200, 0.1331, 0.6917, 0.0551],\n",
      "         [0.4060, 0.2222, 0.1801, 0.1917],\n",
      "         [0.0600, 0.4411, 0.3206, 0.1782],\n",
      "         [0.5375, 0.3742, 0.0723, 0.0160]],\n",
      "\n",
      "        [[0.1206, 0.1870, 0.1274, 0.5650],\n",
      "         [0.2734, 0.4159, 0.1795, 0.1312],\n",
      "         [0.0117, 0.0482, 0.2077, 0.7324],\n",
      "         [0.3335, 0.0671, 0.0239, 0.5756]],\n",
      "\n",
      "        [[0.2491, 0.5251, 0.0100, 0.2159],\n",
      "         [0.6301, 0.2159, 0.0275, 0.1265],\n",
      "         [0.0382, 0.4350, 0.3779, 0.1489],\n",
      "         [0.0096, 0.3531, 0.5097, 0.1276]],\n",
      "\n",
      "        [[0.0276, 0.3762, 0.2680, 0.3282],\n",
      "         [0.4595, 0.1092, 0.1352, 0.2960],\n",
      "         [0.0380, 0.2342, 0.5269, 0.2009],\n",
      "         [0.2084, 0.1432, 0.4407, 0.2077]]]) tensor([[[0.1185, 0.1185, 0.5764, 0.1866],\n",
      "         [0.4043, 0.2177, 0.1795, 0.1985],\n",
      "         [0.1154, 0.3745, 0.2777, 0.2324],\n",
      "         [0.4497, 0.4024, 0.0790, 0.0688]],\n",
      "\n",
      "        [[0.1461, 0.1751, 0.1549, 0.5239],\n",
      "         [0.2476, 0.4175, 0.1594, 0.1755],\n",
      "         [0.0850, 0.1360, 0.1840, 0.5949],\n",
      "         [0.2653, 0.1960, 0.0947, 0.4441]],\n",
      "\n",
      "        [[0.1362, 0.2566, 0.0937, 0.5136],\n",
      "         [0.5837, 0.2041, 0.0873, 0.1250],\n",
      "         [0.0740, 0.4104, 0.3653, 0.1503],\n",
      "         [0.0706, 0.3370, 0.4739, 0.1185]],\n",
      "\n",
      "        [[0.0622, 0.3450, 0.2720, 0.3208],\n",
      "         [0.3889, 0.1260, 0.1400, 0.3450],\n",
      "         [0.1111, 0.2008, 0.5102, 0.1779],\n",
      "         [0.2048, 0.1729, 0.4209, 0.2013]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "phi_param = pyro.param(\"phi_param\")\n",
    "softmax = nn.Softmax(-1)\n",
    "phi1 = softmax(phi_param)\n",
    "\n",
    "print(phi0, phi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4047, 0.4316, 0.4005, 0.4183],\n",
       "        [0.4037, 0.4333, 0.4187, 0.4193],\n",
       "        [0.4002, 0.4258, 0.3995, 0.4078],\n",
       "        [0.3998, 0.4361, 0.4014, 0.4266],\n",
       "        [0.4183, 0.4409, 0.3965, 0.4221],\n",
       "        [0.3945, 0.4356, 0.3975, 0.4178],\n",
       "        [0.3947, 0.4178, 0.3985, 0.4057],\n",
       "        [0.3776, 0.4040, 0.3808, 0.4043],\n",
       "        [0.3636, 0.3942, 0.3628, 0.3956],\n",
       "        [0.3590, 0.3821, 0.3652, 0.3845],\n",
       "        [0.3308, 0.3724, 0.3576, 0.3621],\n",
       "        [0.3282, 0.3670, 0.3376, 0.3647],\n",
       "        [0.3230, 0.3531, 0.3257, 0.3509],\n",
       "        [0.3155, 0.3454, 0.3296, 0.3357],\n",
       "        [0.3256, 0.3316, 0.3235, 0.3146],\n",
       "        [0.2793, 0.3156, 0.2883, 0.3027],\n",
       "        [0.2725, 0.3002, 0.2753, 0.2901],\n",
       "        [0.2467, 0.2604, 0.2471, 0.2579],\n",
       "        [0.2211, 0.2359, 0.2251, 0.2363],\n",
       "        [0.1877, 0.1889, 0.1887, 0.1927]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwm_param = pyro.param(\"pwm_param\")\n",
    "pwm_param[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(pwm0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19) tensor(5)\n",
      "tensor(9) tensor(7)\n",
      "tensor(12) tensor(19)\n"
     ]
    }
   ],
   "source": [
    "w_param = pyro.param(\"w_param\")\n",
    "w1 = [DiscretizedBeta(5, 21, w_param[j, 0], w_param[j, 1])\n",
    "      for j in range(r)]\n",
    "for j in range(r):\n",
    "      print(w1[j].sample(), w0[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xoh = F.one_hot(X, 4).float()\n",
    "Xoh = torch.permute(Xoh, (0, 2, 1))\n",
    "\n",
    "I_param = motif_cnn.predict_I(Xoh)\n",
    "I1 = dist.Categorical(I_param)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b08fbbdb625a1bd47f2df3b9a6d08aa77f5ee8b60b707c6c4c23898f6e322d6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pyro-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
